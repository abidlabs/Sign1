{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of OpenCV + FastAI + MobileNetV2 for video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T06:12:41.825086Z",
     "iopub.status.busy": "2020-09-24T06:12:41.824906Z",
     "iopub.status.idle": "2020-09-24T06:12:41.876433Z",
     "shell.execute_reply": "2020-09-24T06:12:41.875917Z",
     "shell.execute_reply.started": "2020-09-24T06:12:41.825065Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()\n",
    "\n",
    "# from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import fastai.vision\n",
    "import fastai\n",
    "from fastai.learner import *\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:24:56.807166Z",
     "iopub.status.busy": "2020-09-24T07:24:56.806980Z",
     "iopub.status.idle": "2020-09-24T07:24:56.829932Z",
     "shell.execute_reply": "2020-09-24T07:24:56.829420Z",
     "shell.execute_reply.started": "2020-09-24T07:24:56.807146Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'dls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-736431910f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# learn_inf = load_learner(path/'200922-0716-FALL-lrfoc4-ulrfoc2-ulrfoc2')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../models/save/200923-2300-MOBILENET2-PYTORCHONLY-FALL-ft6f3.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_fp32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'dls'"
     ]
    }
   ],
   "source": [
    "path = '../models'\n",
    "# learn_inf = load_learner(path/'200922-0716-FALL-lrfoc4-ulrfoc2-ulrfoc2')\n",
    "learn_inf = load_learner(f'../models/save/200923-2300-MOBILENET2-PYTORCHONLY-FALL-ft6f3.pth')\n",
    "\n",
    "\n",
    "# learn_inf = load_learner(path/'200921-0600-FALL-lrfoc4-ulrfoc6-F-lrfoc4-ulrfoc6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_camera() -> cv.VideoCapture:\n",
    "    '''\n",
    "    Set up the camera source\n",
    "    '''\n",
    "#     cap = cv.VideoCapture(0)\n",
    "    # cap = cv.VideoCapture('http://127.0.0.1:4747/video')\n",
    "    cap = cv.VideoCapture('http://10.0.0.75:4747/video')\n",
    "    # cap = cv.VideoCapture('Droidcam')\n",
    "    # cap = cv.VideoCapture('http://10.0.0.145:4747/video')\n",
    "    \n",
    "    print(f'Autofocus status: {cap.set(cv.CAP_PROP_AUTOFOCUS, 0)}')\n",
    "    print(f'Manual focus to shortest distance: {cap.set(cv.CAP_PROP_FOCUS, 0)}')\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file!\")\n",
    "    \n",
    "    return cap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def close_camera():\n",
    "    '''\n",
    "    Close all capture devices and destroy open capture windows\n",
    "    '''\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def print_stats():\n",
    "    '''\n",
    "    Print some basic stats to stdout\n",
    "    '''\n",
    "    \n",
    "    print(f'Frame shape = {frame.shape}')\n",
    "    print(f'Total number of Frames = {nframe}')\n",
    "    print(f'Number of frames processed = {n_proc_frames // PROC_NTH_FRAME}')\n",
    "    \n",
    "    \n",
    "    \n",
    "# @TODO: Factor out the directory creation logic - slow/redundant    \n",
    "def save_images(frame, prframe):\n",
    "    '''\n",
    "    write small and large images to jpeg\n",
    "    '''\n",
    "    symbol_dir = SYMBOL\n",
    "    \n",
    "    #seperate the directory path\n",
    "    datadir_small = f'../data/{maindir}-S/{symbol_dir}'\n",
    "    datadir_large = f'../data/{maindir}-L/{symbol_dir}'\n",
    "\n",
    "    # build the entire directory structure if it doesn't exist\n",
    "    if not os.path.isdir(datadir_small):\n",
    "        os.makedirs(datadir_small)\n",
    "        \n",
    "    if not os.path.isdir(datadir_large):\n",
    "        os.makedirs(datadir_large)\n",
    "    \n",
    "    # create a directory+filename template\n",
    "    ftemplate_small = f'{datadir_small}/{file_prefix}-{n_proc_frames}.jpg'\n",
    "    ftemplate_large = f'{datadir_large}/{file_prefix}-{n_proc_frames}.jpg'\n",
    "    \n",
    "    # write the image to a file\n",
    "#     cv.imwrite(ftemplate_small, prframe)\n",
    "    cv.imwrite(ftemplate_large, frame)\n",
    "    \n",
    "    frame = cv.putText(frame, f'Saved Frame #{n_proc_frames}', \n",
    "                   org=(20,40), fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                   fontScale=2, color=(0,255,255), thickness=2,\n",
    "                   lineType=cv.LINE_AA) \n",
    "    \n",
    "    # Display the frame with the writing on it\n",
    "    cv.imshow('What the Camera Sees:',frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Open the video camera, loop for every Frame, massage the image and make a prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the main code cel.  It has 2 purposes. When you hit the spacebar, it will either:\n",
    "1. Make an ASL alphabet translation or \n",
    "2. If SAVE_IMAGES_TO_FILE is True, it will save an image to the data dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROC_NTH_FRAME = 8  # Skip every N-1 frames - increase this if your computer lags\n",
    "SAVE_IMAGES_TO_FILE = False  # flag if we want to capture the image to disk\n",
    "\n",
    "maindir = 'frank-ledlights'\n",
    "file_prefix = 'oldwebcam'\n",
    "\n",
    "n_proc_frames, nframe = 0,0  # number of frames\n",
    "\n",
    "# declare here to widen scope\n",
    "pred, probs, pred_idx = [0], [0], 0\n",
    "frame, prframe = None, None\n",
    "\n",
    "if SAVE_IMAGES_TO_FILE:\n",
    "    SYMBOL = input('Enter Symbol of interest: ')[0]\n",
    "    \n",
    "cap = setup_camera()\n",
    "\n",
    "\n",
    "# \"Game\" Loop ... for every frame\n",
    "while(cap.isOpened()):\n",
    "    nframe += 1\n",
    "    ret, frame = cap.read()  # Capture frame\n",
    "    wait_ret = cv.waitKey(2)  # key char value if any\n",
    "\n",
    "    # Break out of the loop if the user presses 'Q'\n",
    "    if wait_ret & 0xFF == ord('q'):\n",
    "        print_stats()\n",
    "        break\n",
    "    \n",
    "    # only process the rest if the capture was successful\n",
    "    if not ret:\n",
    "        print(\"Can't read frame from capture source!\")\n",
    "        break  # break out of loop to let the camera close\n",
    "\n",
    "    # crop the original 640x480 image down to a centered square 480x480\n",
    "    frame = frame[:, 80:-80]\n",
    "\n",
    "    # mirror the image horizontally\n",
    "    frame = cv.flip(frame, 1)\n",
    "\n",
    "\n",
    "    # process only if the space key is hit and\n",
    "    # only process every PROC_NTH_FRAME frames \n",
    "    if (nframe % PROC_NTH_FRAME == 0):  # wait_ret & 0xFF == ord(' ') and \n",
    "        n_proc_frames +=1  # num processed frames\n",
    "\n",
    "        # resize the image to 128x128 after \"zooming in\"\n",
    "#         prframe = cv.resize(frame[60:-60, 60:-60], (128,128))\n",
    "\n",
    "        # this version for resnet 34 w/ 300px image\n",
    "        prframe = cv.resize(frame[60:-60, 60:-60], (300,300))\n",
    "\n",
    "        \n",
    "        # Display the frame that we pass through the predictor\n",
    "        cv.imshow('What the Predictor Sees:', prframe)\n",
    "\n",
    "        if SAVE_IMAGES_TO_FILE :\n",
    "            save_images(frame, prframe)\n",
    "            continue  # no need to predict\n",
    "\n",
    "        # create the prediction\n",
    "        pred,pred_idx,probs = learn_inf.predict(prframe)\n",
    "\n",
    "\n",
    "    # write the prediction as text on the frame\n",
    "    if probs[pred_idx] > 0.75:\n",
    "        frame = cv.putText(frame, f'Predict: {pred}, prob: {probs[pred_idx]:.02f}', \n",
    "                           org=(20,40), fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                           fontScale=2, color=(0,255,255), thickness=2,\n",
    "                           lineType=cv.LINE_AA) \n",
    "\n",
    "    # Display the original frame\n",
    "    cv.imshow('What the Camera Sees:',frame)\n",
    "\n",
    "# Release the capture object\n",
    "close_camera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.destroyAllWindows()                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-19T09:52:40.639847Z",
     "iopub.status.busy": "2020-09-19T09:52:40.639632Z",
     "iopub.status.idle": "2020-09-19T09:52:40.642608Z",
     "shell.execute_reply": "2020-09-19T09:52:40.642059Z",
     "shell.execute_reply.started": "2020-09-19T09:52:40.639824Z"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# The rest of this file is for reference only.  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Snippets\n",
    "\n",
    "```python\n",
    "# rotate the image\n",
    "frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
